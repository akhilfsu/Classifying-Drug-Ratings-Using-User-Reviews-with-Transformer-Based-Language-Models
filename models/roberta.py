# -*- coding: utf-8 -*-
"""LRFroBERT.ipynb

Automatically generated by Colaboratory.


"""

!pip install --upgrade pip -q
!pip install -q ktrain

# Generic
import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import warnings, gc
warnings.filterwarnings("ignore")


# Tensorflow
import tensorflow as tf

# ktrain
import ktrain
from ktrain import text

# sklearn
from sklearn.model_selection import train_test_split

from google.colab import files
upload = files.upload()

from google.colab import files
upload = files.upload()

df = pd.read_csv("drugsComTrain_raw.tsv", sep='\t')
df.info()
df['review'].str.len().plot()
maxer=df[df['review'].str.len()>1000]
maxer.info()



df1 = pd.read_csv("drugsComTrain_raw.tsv", sep='\t')

df1.info()
p=df1[df1['review'].str.len()<=1000]
df1=p
drug1=pd.cut(df1.rating,bins=[0,8.00000,10],labels=[0,1],) 
df1.insert(3,'test',drug1) ##insert the review score
df1.head(4)

df2 = pd.read_csv("drugsComTest_raw.tsv", sep='\t')

df2.info()
p=df2[df2['review'].str.len()<=1000]
df2=p
drug1=pd.cut(df2.rating,bins=[0,8.00000,10],labels=[0,1],) 
df2.insert(3,'test',drug1) ##insert the review score
df2.head(4)

frames = [df1, df2]
df = pd.concat(frames)



df.info()

from sklearn.model_selection import train_test_split

train, testing = train_test_split(df, test_size=0.2, random_state=41)

df=train

train["rating"].mean()

train["rating"].median()

testing["rating"].median()

testing["rating"].mean()

# Data Split
target = ['test']
data = ['review']

X = df[data]
y = df[target]

X_train, X_test, y_train, y_test = train_test_split(X, y , test_size=0.25, random_state=42)

# Common Parameters
max_len = 512
batch_size = 6
learning_rate = 5e-5
epochs = 12

my_callbacks = [
    tf.keras.callbacks.EarlyStopping(patience=2),
    tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5'),
    tf.keras.callbacks.TensorBoard(log_dir='./logs'),
]
# Data Split
target = ['test']
data = ['review']

X = df[data]
y = df[target]

X_train, X_test, y_train, y_test = train_test_split(X, y , test_size=0.2, random_state=42)
# Transformer electra
model_ ="roberta-base"
t_mod = text.Transformer(model_, classes = [0,1], maxlen=512)


'''Converting split data to list [so it can processed]'''
#train
X_tr = X_train['review'].tolist()
y_tr = y_train['test'].tolist()

#test
X_ts = X_test['review'].tolist()
y_ts = y_test['test'].tolist()


# Pre-processing training & test data
train = t_mod.preprocess_train(X_tr,y_tr)
test = t_mod.preprocess_train(X_ts,y_ts)

# Model Classifier
model = t_mod.get_classifier()

learner = ktrain.get_learner(model, train_data=train, val_data=test, batch_size=6)
learner.fit_onecycle(learning_rate, epochs = 14, callbacks=my_callbacks)
e = learner.validate(class_names=t_mod.get_classes())





from google.colab import drive
drive.mount('/content/gdrive')

predictor = ktrain.get_predictor(learner.model, t_mod)

model_save_name = 'roBERT.pt'
path = F"/content/gdrive/My Drive/{model_save_name}" 
predictor.save(path)

testing

reloaded_predictor = ktrain.load_predictor(path)

a=testing['review'].tolist()
a

c=predictor.predict(a)

from pandas import DataFrame
df_pred = DataFrame(c,columns=['pred'])

df_pred

true=testing['test'].tolist()

df_true = DataFrame(true,columns=['true'])
df_true.head()

import sklearn
from sklearn.metrics import confusion_matrix

sklearn.metrics.confusion_matrix(df_true["true"], df_pred["pred"], labels=[0,1])

from sklearn.metrics import f1_score

sklearn.metrics.f1_score(df_true["true"], df_pred["pred"], labels=[0,1])

from sklearn.metrics import classification_report
matrix = classification_report(df_true["true"],df_pred["pred"],labels=[1,0])

matrix

precision    recall  f1-score   support

           1       0.79      0.93      0.86     21056
           0       0.92      0.76      0.83     21877

    accuracy                           0.85     42933
   macro avg       0.86      0.85      0.85     42933
weighted avg       0.86      0.85      0.85     42933

testing.reindex()

df=testing

anxiety=df[df['condition']=='Anxiety']

df.info()

anxiety.info()

anxiety.head()



a=anxiety['review'].tolist()
a

c=predictor.predict(a)

from pandas import DataFrame
df_pred = DataFrame(c,columns=['pred'])

df_pred

df_pred.info()

true=anxiety['test'].tolist()

df_true = DataFrame(true,columns=['true'])
df_true.head()

import sklearn
from sklearn.metrics import confusion_matrix

sklearn.metrics.confusion_matrix(df_true["true"], df_pred["pred"], labels=[0,1])

from sklearn.metrics import f1_score

sklearn.metrics.f1_score(df_true["true"], df_pred["pred"], labels=[0,1])

from sklearn.metrics import classification_report
matrix = classification_report(df_true["true"],df_pred["pred"],labels=[1,0])

matrix

precision    recall  f1-score   support

           1       0.82      0.98      0.89       733
           0       0.95      0.69      0.80       518

    accuracy                           0.86      1251
   macro avg       0.88      0.83      0.84      1251
weighted avg       0.87      0.86      0.85      1251

def speed():
  a=anxiety['review'].tolist()
  a

  c=predictor.predict(a)

  from pandas import DataFrame
  df_pred = DataFrame(c,columns=['pred'])

  df_pred

  true=anxiety['test'].tolist()

  df_true = DataFrame(true,columns=['true'])
  df_true.head()

  import sklearn
  from sklearn.metrics import confusion_matrix

  sklearn.metrics.confusion_matrix(df_true["true"], df_pred["pred"], labels=[0,1])

  from sklearn.metrics import f1_score

  sklearn.metrics.f1_score(df_true["true"], df_pred["pred"], labels=[0,1])

  from sklearn.metrics import classification_report
  matrix = classification_report(df_true["true"],df_pred["pred"],labels=[1,0])


  return matrix

df["condition"].value_counts().head(50)

anxiety=df[df['condition']=='Birth Control']

speed()

precision    recall  f1-score   support

           1       0.79      0.95      0.86      2104
           0       0.97      0.87      0.92      4018

    accuracy                           0.89      6122
   macro avg       0.88      0.91      0.89      6122
weighted avg       0.91      0.89      0.90      6122

anxiety=df[df['condition']=='Depression']

speed()

precision    recall  f1-score   support

           1       0.79      0.97      0.87       912
           0       0.96      0.77      0.86      1015

    accuracy                           0.87      1927
   macro avg       0.88      0.87      0.86      1927
weighted avg       0.88      0.87      0.86      1927

anxiety=df[df['condition']=='Pain']

speed()

precision    recall  f1-score   support

           1       0.80      0.97      0.88       706
           0       0.94      0.70      0.80       564

    accuracy                           0.85      1270
   macro avg       0.87      0.83      0.84      1270
weighted avg       0.86      0.85      0.84      1270

anxiety=df[df['condition']=='Acne']

speed()

precision    recall  f1-score   support

           1       0.82      0.97      0.89       578
           0       0.97      0.78      0.87       557

    accuracy                           0.88      1135
   macro avg       0.89      0.88      0.88      1135
weighted avg       0.89      0.88      0.88      1135

anxiety=df[df['condition']=='Bipolar Disorde']

speed()

precision    recall  f1-score   support

           1       0.79      0.98      0.88       466
           0       0.97      0.74      0.84       466

    accuracy                           0.86       932
   macro avg       0.88      0.86      0.86       932
weighted avg       0.88      0.86      0.86       932

anxiety=df[df['condition']=='Insomnia']

speed()

precision    recall  f1-score   support

           1       0.80      0.96      0.87       391
           0       0.95      0.78      0.85       427

    accuracy                           0.86       818
   macro avg       0.87      0.87      0.86       818
weighted avg       0.88      0.86      0.86       818

anxiety=df[df['condition']=='Weight Loss']

speed()

precision    recall  f1-score   support

           1       0.86      0.94      0.90       487
           0       0.88      0.71      0.79       266

    accuracy                           0.86       753
   macro avg       0.87      0.83      0.84       753
weighted avg       0.86      0.86      0.86       753

precision    recall  f1-score   support

           1       0.86      0.94      0.90       487
           0       0.88      0.71      0.79       266

    accuracy                           0.86       753
   macro avg       0.87      0.83      0.84       753
weighted avg       0.86      0.86      0.86       753

anxiety=df[df['condition']=='Obesity']

speed()

precision    recall  f1-score   support

           1       0.84      0.93      0.88       429
           0       0.89      0.75      0.81       307

    accuracy                           0.85       736
   macro avg       0.86      0.84      0.85       736
weighted avg       0.86      0.85      0.85       736

anxiety=df[df['condition']=='ADHD']

speed()

precision    recall  f1-score   support

           1       0.79      0.98      0.88       365
           0       0.98      0.75      0.85       366

    accuracy                           0.86       731
   macro avg       0.89      0.86      0.86       731
weighted avg       0.89      0.86      0.86       731

anxiety=df[df['condition']=='Diabetes, Type 2']

speed()

