# -*- coding: utf-8 -*-
"""LRfelectra.ipynb

Automatically generated by Colaboratory.


"""

!pip install --upgrade pip -q
!pip install -q ktrain

from google.colab import drive
drive.mount('/content/gdrive')

# Generic
import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import warnings, gc
warnings.filterwarnings("ignore")


# Tensorflow
import tensorflow as tf

# ktrain
import ktrain
from ktrain import text

# sklearn
from sklearn.model_selection import train_test_split

from google.colab import files
upload = files.upload()

from google.colab import files
upload = files.upload()

df = pd.read_csv("drugsComTrain_raw.tsv", sep='\t')
df.info()
df['review'].str.len().plot()
maxer=df[df['review'].str.len()>1000]
maxer.info()



df1 = pd.read_csv("drugsComTrain_raw.tsv", sep='\t')

df1.info()
p=df1[df1['review'].str.len()<=1000]
df1=p
drug1=pd.cut(df1.rating,bins=[0,8.00000,10],labels=[0,1],) 
df1.insert(3,'test',drug1) ##insert the review score
df1.head(4)

df2 = pd.read_csv("drugsComTest_raw.tsv", sep='\t')

df2.info()
p=df2[df2['review'].str.len()<=1000]
df2=p
drug1=pd.cut(df2.rating,bins=[0,8.00000,10],labels=[0,1],) 
df2.insert(3,'test',drug1) ##insert the review score
df2.head(4)

frames = [df1, df2]
df = pd.concat(frames)

df.info()

from sklearn.model_selection import train_test_split

train, testing = train_test_split(df, test_size=0.2, random_state=41)

df=train

train["rating"].mean()

train["rating"].median()

testing["rating"].median()

testing["rating"].mean()

# Data Split
target = ['test']
data = ['review']

X = df[data]
y = df[target]

X_train, X_test, y_train, y_test = train_test_split(X, y , test_size=0.25, random_state=42)

# Common Parameters
max_len = 512
batch_size = 6
learning_rate = 5e-5
epochs = 12

my_callbacks = [
    tf.keras.callbacks.EarlyStopping(patience=2),
    tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5'),
    tf.keras.callbacks.TensorBoard(log_dir='./logs'),
]
# Data Split
target = ['test']
data = ['review']

X = df[data]
y = df[target]

X_train, X_test, y_train, y_test = train_test_split(X, y , test_size=0.2, random_state=42)
# Transformer electra
model_ ="google/electra-base-discriminator"
t_mod = text.Transformer(model_, classes = [0,1], maxlen=512)


'''Converting split data to list [so it can processed]'''
#train
X_tr = X_train['review'].tolist()
y_tr = y_train['test'].tolist()

#test
X_ts = X_test['review'].tolist()
y_ts = y_test['test'].tolist()


# Pre-processing training & test data
train = t_mod.preprocess_train(X_tr,y_tr)
test = t_mod.preprocess_train(X_ts,y_ts)

# Model Classifier
model = t_mod.get_classifier()

learner = ktrain.get_learner(model, train_data=train, val_data=test, batch_size=6)
learner.fit_onecycle(learning_rate, epochs = 14, callbacks=my_callbacks)
e = learner.validate(class_names=t_mod.get_classes())

predictor = ktrain.get_predictor(learner.model, t_mod)

model_save_name = 'Electra.pt'
path = F"/content/gdrive/My Drive/{model_save_name}" 
predictor.save(path)

testing

reloaded_predictor = ktrain.load_predictor(path)

a=testing['review'].tolist()
a

c=predictor.predict(a)

from pandas import DataFrame
df_pred = DataFrame(c,columns=['pred'])

df_pred

true=testing['test'].tolist()

df_true = DataFrame(true,columns=['true'])
df_true.head()

import sklearn
from sklearn.metrics import confusion_matrix

sklearn.metrics.confusion_matrix(df_true["true"], df_pred["pred"], labels=[0,1])

from sklearn.metrics import f1_score

sklearn.metrics.f1_score(df_true["true"], df_pred["pred"], labels=[0,1])

from sklearn.metrics import classification_report
matrix = classification_report(df_true["true"],df_pred["pred"],labels=[1,0])

matrix

precision    recall  f1-score   support

           1       0.90      0.81      0.85     21056
           0       0.83      0.92      0.87     21877

    accuracy                           0.86     42933
   macro avg       0.87      0.86      0.86     42933
weighted avg       0.87      0.86      0.86     42933

testing.reindex()

df=testing

anxiety=df[df['condition']=='Anxiety']

df.info()

anxiety.info()

anxiety.head()



a=anxiety['review'].tolist()
a

c=predictor.predict(a)

from pandas import DataFrame
df_pred = DataFrame(c,columns=['pred'])

df_pred

df_pred.info()

true=anxiety['test'].tolist()

df_true = DataFrame(true,columns=['true'])
df_true.head()

import sklearn
from sklearn.metrics import confusion_matrix

sklearn.metrics.confusion_matrix(df_true["true"], df_pred["pred"], labels=[0,1])

from sklearn.metrics import f1_score

sklearn.metrics.f1_score(df_true["true"], df_pred["pred"], labels=[0,1])

from sklearn.metrics import classification_report
matrix = classification_report(df_true["true"],df_pred["pred"],labels=[1,0])

matrix

precision    recall  f1-score   support

           1       0.88      0.83      0.86       893
           0       0.79      0.84      0.81       649

    accuracy                           0.84      1542
   macro avg       0.83      0.84      0.83      1542
weighted avg       0.84      0.84      0.84      1542

def speed():
  a=anxiety['review'].tolist()
  a

  c=predictor.predict(a)

  from pandas import DataFrame
  df_pred = DataFrame(c,columns=['pred'])

  df_pred

  true=anxiety['test'].tolist()

  df_true = DataFrame(true,columns=['true'])
  df_true.head()

  import sklearn
  from sklearn.metrics import confusion_matrix

  sklearn.metrics.confusion_matrix(df_true["true"], df_pred["pred"], labels=[0,1])

  from sklearn.metrics import f1_score

  sklearn.metrics.f1_score(df_true["true"], df_pred["pred"], labels=[0,1])

  from sklearn.metrics import classification_report
  matrix = classification_report(df_true["true"],df_pred["pred"],labels=[1,0])


  return matrix

df["condition"].value_counts().head(50)

anxiety=df[df['condition']=='Birth Control']

speed()

anxiety=df[df['condition']=='Depression']

speed()

anxiety=df[df['condition']=='Pain']

speed()

precision    recall  f1-score   support

           1       0.88      0.83      0.85       938
           0       0.80      0.87      0.83       781

    accuracy                           0.84      1719
   macro avg       0.84      0.85      0.84      1719
weighted avg       0.85      0.84      0.84      1719

precision    recall  f1-score   support\n\n           1       0.88      0.83      0.85       938\n           0       0.80      0.87      0.83       781\n\n    accuracy                           0.84      1719\n   macro avg       0.84      0.85      0.84      1719\nweighted avg       0.85      0.84      0.84      1719\n

anxiety=df[df['condition']=='Acne']

speed()

precision    recall  f1-score   support

           1       0.89      0.82      0.86       816
           0       0.81      0.88      0.84       672

    accuracy                           0.85      1488
   macro avg       0.85      0.85      0.85      1488
weighted avg       0.85      0.85      0.85      1488

anxiety=df[df['condition']=='Bipolar Disorde']

speed()

precision    recall  f1-score   support

           1       0.87      0.81      0.84       512
           0       0.84      0.89      0.87       577

    accuracy                           0.86      1089
   macro avg       0.86      0.85      0.85      1089
weighted avg       0.86      0.86      0.86      1089

anxiety=df[df['condition']=='Insomnia']

speed()

precision    recall  f1-score   support

           1       0.88      0.78      0.82       499
           0       0.82      0.90      0.86       556

    accuracy                           0.84      1055
   macro avg       0.85      0.84      0.84      1055
weighted avg       0.85      0.84      0.84      1055

anxiety=df[df['condition']=='Weight Loss']

speed()

precision    recall  f1-score   support

           1       0.90      0.85      0.87       581
           0       0.76      0.85      0.80       337

    accuracy                           0.85       918
   macro avg       0.83      0.85      0.84       918
weighted avg       0.85      0.85      0.85       918

anxiety=df[df['condition']=='Obesity']

speed()

precision    recall  f1-score   support

           1       0.84      0.81      0.82       550
           0       0.76      0.79      0.77       416

    accuracy                           0.80       966
   macro avg       0.80      0.80      0.80       966
weighted avg       0.80      0.80      0.80       966

anxiety=df[df['condition']=='ADHD']

speed()

precision    recall  f1-score   support

           1       0.93      0.79      0.86       443
           0       0.82      0.94      0.88       449

    accuracy                           0.87       892
   macro avg       0.87      0.87      0.87       892
weighted avg       0.87      0.87      0.87       892

anxiety=df[df['condition']=='Diabetes, Type 2']

speed()

